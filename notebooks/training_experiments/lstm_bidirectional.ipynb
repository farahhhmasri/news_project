{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\vsCode\\news_project\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import mlflow \n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.18.0'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>news</th>\n",
       "      <th>neg</th>\n",
       "      <th>neu</th>\n",
       "      <th>pos</th>\n",
       "      <th>compound</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>It was a long antipodean night. While thereâ€™s ...</td>\n",
       "      <td>0.059</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.0516</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>In Mexico there are no licensing or registrati...</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.956</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>NEGATIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-07-07</td>\n",
       "      <td>The government has until Monday to protect the...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>POSITIVE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                               news    neg  \\\n",
       "0  2007-07-07  It was a long antipodean night. While thereâ€™s ...  0.059   \n",
       "1  2007-07-07  In Mexico there are no licensing or registrati...  0.044   \n",
       "2  2007-07-07  The government has until Monday to protect the...  0.000   \n",
       "\n",
       "     neu    pos  compound sentiment  \n",
       "0  0.878  0.064    0.0516  POSITIVE  \n",
       "1  0.956  0.000   -0.2960  NEGATIVE  \n",
       "2  0.894  0.106    0.3818  POSITIVE  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try:\n",
    "    if 'dataset' not in os.listdir(\"../\"):\n",
    "        print(\"Dataset doesn't exist, downloading it...\")\n",
    "        os.makedirs('../dataset/', exist_ok=True)\n",
    "        path = kagglehub.dataset_download(\"myrios/news-sentiment-analysis\")\n",
    "        print(f\"Dataset original path: {path}\")\n",
    "        shutil.move(path, '../dataset/')\n",
    "        path = \"dataset/news.csv\"\n",
    "        print(\"Dataset was downloaded and put in dataset/ directory.\")\n",
    "    else:\n",
    "        path = \"../dataset/news.csv\"\n",
    "        print(\"Loading news dataset... \")\n",
    "        print(f\"Dataset path: {path}\")\n",
    "        \n",
    "    \n",
    "except Exception as e :\n",
    "    print(f\"Dataset loading error: {e}\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(f\"{path}\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if text[0] == 'b':\n",
    "        text= text[1:]\n",
    "    if text[0] == '\"' or text[0] == \"'\":\n",
    "        text = text[1:len(text)-1]  \n",
    "    text = re.sub(r'\\\\+', r'\\\\', text)\n",
    "    text = re.sub(r'(?<!\\d)\\\\(?!\\d)', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['sentiment'].map(lambda s: 1 if s == 'POSITIVE' else 0)\n",
    "df['clean_news'] = df['news'].map(lambda t: clean_text(t))\n",
    "BUFFER_SIZE = df.shape[0]\n",
    "BATCH_SIZE  = 64\n",
    "dataset = tf.data.Dataset.from_tensor_slices((df[\"news\"].values, df[\"label\"].values))\n",
    "\n",
    "test_size = int(0.2 * len(df))\n",
    "train_dataset = dataset.skip(test_size)\n",
    "test_dataset = dataset.take(test_size)\n",
    "\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 1000\n",
    "encoder = tf.keras.layers.TextVectorization(max_tokens=VOCAB_SIZE)\n",
    "encoder.adapt(train_dataset.map(lambda text, label: text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['', '[UNK]', 'the', 'a', 'of', 'to', 'and', 'in', 'for', 'on',\n",
       "       'is', 'that', 'with', 'at', 'as', 'are', 'new', 'from', 'an',\n",
       "       'his'], dtype='<U16')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = np.array(encoder.get_vocabulary())\n",
    "vocab[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get('val_loss') <= 0.15:\n",
    "            print(\"\\nModel performed good on validation data, stopping training!\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "callbacks = MyCallback()\n",
    "earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    encoder,\n",
    "    tf.keras.layers.Embedding(input_dim=len(encoder.get_vocabulary()), output_dim=64, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(64)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m5344/5344\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 85ms/step - accuracy: 0.6610 - loss: 0.5632 - val_accuracy: 0.7635 - val_loss: 0.5618\n",
      "Epoch 2/15\n",
      "\u001b[1m5344/5344\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 96ms/step - accuracy: 0.7282 - loss: 0.4973 - val_accuracy: 0.7599 - val_loss: 0.5604\n",
      "Epoch 3/15\n",
      "\u001b[1m5344/5344\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m550s\u001b[0m 103ms/step - accuracy: 0.7328 - loss: 0.4905 - val_accuracy: 0.7266 - val_loss: 0.5973\n",
      "Epoch 4/15\n",
      "\u001b[1m5344/5344\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m589s\u001b[0m 110ms/step - accuracy: 0.7379 - loss: 0.4837 - val_accuracy: 0.7328 - val_loss: 0.5922\n",
      "Epoch 5/15\n",
      "\u001b[1m5344/5344\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m778s\u001b[0m 145ms/step - accuracy: 0.7384 - loss: 0.4814 - val_accuracy: 0.7469 - val_loss: 0.5746\n",
      "Epoch 6/15\n",
      "\u001b[1m5344/5344\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m716s\u001b[0m 134ms/step - accuracy: 0.7409 - loss: 0.4779 - val_accuracy: 0.7172 - val_loss: 0.5936\n",
      "Epoch 7/15\n",
      "\u001b[1m5344/5344\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m682s\u001b[0m 128ms/step - accuracy: 0.7424 - loss: 0.4750 - val_accuracy: 0.7323 - val_loss: 0.5875\n",
      "Epoch 8/15\n",
      "\u001b[1m5344/5344\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m732s\u001b[0m 137ms/step - accuracy: 0.7428 - loss: 0.4739 - val_accuracy: 0.7307 - val_loss: 0.5836\n",
      "Epoch 9/15\n",
      "\u001b[1m5344/5344\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m837s\u001b[0m 157ms/step - accuracy: 0.7470 - loss: 0.4695 - val_accuracy: 0.7094 - val_loss: 0.5963\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_dataset, epochs=15, validation_data=test_dataset, validation_steps=30, callbacks=[callbacks,earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1336/1336\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m109s\u001b[0m 82ms/step - accuracy: 0.7330 - loss: 0.5540\n",
      "Test Loss: 0.5334145426750183\n",
      "Test Accuracy: 0.7383620142936707\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print('Test Loss:', test_loss)\n",
    "print('Test Accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:The `save_format` argument is deprecated in Keras 3. We recommend removing this argument as it can be inferred from the file path. Received: save_format=tf\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# tf.keras.models.save_model(model, \"./bidirectional_LSTM_models/v1.h5\")\n",
    "model.save(\"./training_saved_models/bidirectional_LSTM_models/v1.h5\", save_format=\"tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://localhost:8080\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/03/14 05:07:31 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2025/03/14 05:07:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸƒ View run first training expirement at: http://localhost:8080/#/experiments/659168015968450415/runs/72614fe35527415cb98db56d1dd77393\n",
      "ðŸ§ª View experiment at: http://localhost:8080/#/experiments/659168015968450415\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Biderctional RNN\")\n",
    "\n",
    "params = {\"epochs\": 15,\n",
    "          \"optimizer\":\"adam\",\n",
    "          \"lr\":1e-4,\n",
    "          \"LSTM units\":128}\n",
    "\n",
    "metrics = {\"accuracy\":test_acc}\n",
    "\n",
    "with mlflow.start_run(run_name=\"first training expirement\"):\n",
    "    mlflow.set_tag(\"Model Name\", \"Bidirectional LSTM\")\n",
    "    mlflow.set_tag(\"Model Architecture\", \"One embedding layer, Two Bidirectional LSTM layers (128, 64), Three dense layers (64, 32, 1).\")\n",
    "    mlflow.log_params(params) \n",
    "    mlflow.log_metrics(metrics)\n",
    "\n",
    "    # tag=[tf.compat.v1.saved_model.tag_constants.SERVING]\n",
    "    # key=signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY\n",
    "    mlflow.tensorflow.log_model(model,\n",
    "                                artifact_path= \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
